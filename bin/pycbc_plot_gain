#! /usr/bin/env python

__prog__ = "pycbc_plot_gain"
__author__ = "Collin Capano <collin.capano@ligo.org>"
__description__ = \
"""Creates plots of relative gain between two runs. Will also gather plots
from other progams and place them on the summary pages."""

import os, sys, shutil
from optparse import OptionParser
import numpy
from pycbc import distributions
from pycbc import plot
from pycbc.plot import efficiency
from pycbc.plot import plot_volumes


def get_stat_range(opt):
    stat_info = opt.split(',')
    if len(stat_info) != 2:
        raise ValueError("stat-range not formatted correctly; see help")
    min_stat, max_stat = stat_info
    min_stat = float(min_stat)
    max_stat = float(max_stat)

    return min_stat, max_stat


def get_stat_info(opt):
    stat_info = opt.split(':')
    if len(stat_info) == 1:
        stat = stat_info[0]
        stat_label = stat.replace('_', ' ')
    elif len(stat_info) == 2:
        stat, stat_label = stat_info
    else:
        stat = stat_label = None
    return stat, stat_label


def print_command_line(args):
    """
    Prints the commands given to the program to run; this can be added to the
    bottom of an html page.
    """
    return "Created with:<br />%s" %(' '.join(args))


parser = OptionParser()
parser.add_option('', '--test-cache-file', metavar="TESTFILE.CACHE:TYPE[:TESTLABEL]", help=r'Required. Cache file containing test result files, and their type. The type is the workflow from which the results came. Current type options are %s. All the files in the cache file must come from the same type of workflow. You can also specify a label for the test results; if none provided "test" will be used. The label is in latex math mode; if you want just plain text, enclose in a \textrm{...}. For example, if a cache file called results.cache contained one or more sqlite databases that were created by a pycbc workflow, and you wanted to label this as "pycbc", specify: "results.cache:pycbc_sqlite:\textrm{pycbc}".')
parser.add_option('', '--reference-cache-file',  metavar="REFFILE.CACHE:TYPE[:REFLABEL]", help='Required if reference-stat is not "optimal". Cache file containing reference result databases, and their type. You can also specify a label for the reference results; if none provided "reference" will be used. See test-cache-file for more details.')
parser.add_option('-m', '--map-label', help='Required if either test or reference results type is pycbc_sqlite. The map label to use when getting found injections.')
parser.add_option('-T', '--include-livetime', action='store_true', default=False, help='Calculate gain using VT instead of just V.')
parser.add_option('-l', '--layer-config-file', help='Required. A config file containing the layer parameters to use.') 
parser.add_option('', '--test-threshold', type='float', default=1e-3, help='The value of the ranking stat to use as the threshold when computing efficiencies for the test run. Default is to be equal to 1e-3.')
parser.add_option('', '--reference-threshold', type='float', help='The value of the ranking stat to use as the threshold when computing efficiencies for the reference run. Default is to be the same as test-threshold.')
parser.add_option('-t', '--test-stat', metavar='stat[:stat_label]', default='false_alarm_rate:FAR (yr$^{-1}$)', help='The ranking stat to use for computing efficiency of the test results. Can also specify a stat label for plotting (latex math should be enclosed in $ signs). Default is false_alarm_rate:FAR (yr$^{-1}$).')
parser.add_option('', '--reference-stat', metavar='optimal|stat[:stat_label]', help='Must be either "optimal", or the ranking stat to use for computing efficiency. If "optimal," the results in the test cache file will be compared to what the SNR of each injection would be in Gaussian noise. This is the overlap of each injection with itself ("sigma") divided by 1Mpc. If not "optimal", a reference-cache file must be specified. A stat label for plotting can also be provided if not "optimal." Default is to be the same as test-stat.')
parser.add_option('', '--test-rank-by', metavar='max|min', default='min', help='Options are "max" or "min". If max (min) an injection in the test results will be considered found if its ranking stat is >= (<) the threshold. Default is min.')
parser.add_option('', '--reference-rank-by', metavar='max|min', help='Same as test-rank-by, but for the reference results. Ignored if "reference-stat is "optimal". Default is to be the same as test-rank-by.')
parser.add_option('', '--test-stat-range', metavar='MIN_STAT,MAX_STAT', default='1e-4,1e4', help='Stat range to use when creating volume vs. stat plots for the test results. Must specify both a minimum and a maximum. Default is 1e-4,1e4.')
parser.add_option('', '--reference-stat-range', metavar='MIN_STAT,MAX_STAT', help='Stat range to use when creating volume vs. stat plots for the reference results. Must specify both a minimum and a maximum. Default is to be the same as test-stat-range.')
parser.add_option('', '--log-vol-vs-stat', action='store_true', default=False, help='Make the y-axis of the volume vs ranking-stat plots log10.')
parser.add_option('', '--lin-stat', action='store_true', default=False, help='Make the x-axis of the volume vs ranking-stat plots linear. This will make both the test and reference stats linear. Otherwise, the x-axes are log10.')
parser.add_option('-N', '--min-ninj', type='int', default=10, help='Minimum number of injections that must exist in a block in in order to calculate volume. If a block has less then this, it will be skipped. Default is 10.')
parser.add_option('', '--print-relative-error', action='store_true', default=False, help='Turn on to print relative errors instead of absolute errors.')
parser.add_option('', '--use-distance-bins', action='store_true', default=False, help="If turned on, will use distance bins to compute sensitive volumes, rather than the standard Monte Carlo method of using the average of the integrand. Generally, this will yield larger variance, so turn this on with caution.")
parser.add_option('-A', '--astrophysical-prior', metavar='AST_DISTR.cfg', help='Use the astrophysical prior provided in the given config file. Default is to use whatever was used in the injection set.')
parser.add_option('', '--include-volume-plots', action='store_true', default=False, help='Include the volume tile plots of the test and reference results to the summary html pages.')
parser.add_option('', '--skip-volume-vs-stat-plots', action='store_true', default=False, help="Don't create volume vs. stat plots.")
parser.add_option('-G', '--use-global-norm', action='store_true', default=False, help='Normalize volumes in each tile such that they add up to the total volume across all volumes. In this case, the volumes in each tile give the contribution of that tile to the whole. Otherwise, the volume in each tile is as if the universe only contained signals in that tile.')
parser.add_option('-p', '--additional-plots-cache', metavar='FILE1.cache[,FILE2.cache,...]', help='Load additional plots for each cube from the given cache file(s). To specify multiple cache files, comma separate each file name. All cache files must have used the same layer-configuration-file.')
parser.add_option('-o', '--output-dir', help='Directory to save results to.')
parser.add_option('-u', '--user-tag', default='', help='Add a user tag to all output files.')
parser.add_option('', '--colormap', default='RdBu_r', help='What color map to use for fractional gain plots. Default is RdBu_r.')
parser.add_option('', '--mingain', type='float', default=None, help='Minimum gain to color. If this and maxgain is None, and not --linz, then the gains will be made symmetric about 1, with the range determined by whatever the minimum and maximum gain found is. Otherwise, this will just be set to the minimum gain found.')
parser.add_option('', '--maxgain', type='float', default=None, help='Maximum gain to color. Default is to make symmetric about 1 if no mingain specified and not linz; otherwise, whatever the maximum gain found is.')
parser.add_option('', '--fontsize', type='int', default=8, help='Fontsize to use in volume plots. Default is 8.')
parser.add_option('', '--linz', action='store_true', default=False, help='Make the coloring (and ticks on the sub-gains plot) linear. Default is for these to be log10.')
parser.add_option('', '--dpi', type='int', default=300, help='dpi to use for plots; default is 300')
parser.add_option('-P', '--apply-cut', action = 'append', default = [], metavar = 'arg:min,max', help = 'apply cut to injections; can specify multiple times')
parser.add_option('-M', '--mapper', default=None, help="Specify the location of a mapper.js JavaScript in order to highlight tiles on mouse over.")

opts, _ = parser.parse_args()

if opts.user_tag is not None:
    tag = '_%s' % opts.user_tag
else:
    tag = ''

# set reference options to be the same as test if they are not provided
for opt in ['threshold', 'stat', 'rank_by', 'stat_range']:
    if getattr(opts, 'reference_%s' % opt) is None:
        setattr(opts, 'reference_%s' % opt, getattr(opts, 'test_%s' %opt))

# parse test cache file option
if not opts.test_cache_file:
    raise ValueError('test-cache-file required')
cache_info = opts.test_cache_file.split(':')
if len(cache_info) == 2:
    test_cache, test_results_type = cache_info
    test_label = 'test'
elif len(cache_info) == 3:
    test_cache, test_results_type, test_label = cache_info
else:
    raise ValueError("test-cache-file not formatted correctly; see help")
if test_results_type not in plot.known_pipelines:
    raise ValueError("unrecognized result file type %s; see --test-cache-file help" %(
        test_results_type))
if test_results_type == 'pycbc_sqlite' and opts.map_label is None:
    raise ValueError("test results type is pycbc_sqlite, but no --map-label specified")
if test_results_type == 'overlaps' and opts.include_livetime:
    raise ValueError("cannot include-livetime for overlaps databases")

# parse reference cache file option
if opts.reference_stat != 'optimal':
    if opts.reference_cache_file is None:
        raise ValueError('reference-cache-file must be provided if ' +
            'reference-stat is not "optimal"')
    cache_info = opts.reference_cache_file.split(':')
    if len(cache_info) == 2:
        ref_cache, ref_results_type = cache_info
        ref_label = 'reference'
    elif len(cache_info) == 3:
        ref_cache, ref_results_type, ref_label = cache_info
    else:
        raise ValueError("reference-cache-file not formatted correctly; " +
            "see help")
    if ref_results_type not in plot.known_pipelines:
        raise ValueError("unrecognized result file type %s; "  %(
            ref_results_type) + "see --reference-cache-file help")
    if ref_results_type == 'pycbc_sqlite' and opts.map_label is None:
        raise ValueError("reference results type is pycbc_sqlite, but no " +
            "--map-label specified")
    if ref_results_type == 'overlaps' and opts.include_livetime:
        raise ValueError("cannot include-livetime for overlaps databases")

if not opts.output_dir:
    raise ValueError('output-dir required')

if opts.astrophysical_prior is not None:
    astprior = distributions.load_distribution_from_config(
        opts.astrophysical_prior)
else:
    astprior = None

# set the distance bins option if desired
efficiency.PHyperCube.use_distance_bins = opts.use_distance_bins

test_stat, test_stat_label = get_stat_info(opts.test_stat)
if test_stat is None:
    raise ValueError("test-stat not formatted correctly; see help")
if not (opts.test_rank_by == 'max' or opts.test_rank_by == 'min'):
    raise ValueError('test-rank-by must be set to either "max" or "min"')
test_rank_by = opts.test_rank_by

if opts.reference_stat == 'optimal':
    # format for optimal
    ref_stat = 'optimal_snr'
    ref_stat_label = r'optimal $\rho$'
    ref_rank_by = 'max'
else:
    ref_stat, ref_stat_label = get_stat_info(opts.reference_stat)
    if ref_stat is None:
        raise ValueError("reference-stat not formatted correctly; see help")
    if not (opts.reference_rank_by == 'max' or opts.reference_rank_by == 'min'):
        raise ValueError('reference-rank-by must be set to either "max" or "min"')
    ref_rank_by = opts.reference_rank_by

if opts.test_stat_range is None:
    raise ValueError("test-stat-range must be provided; see help")
test_min_stat, test_max_stat = get_stat_range(opts.test_stat_range)

if opts.reference_stat_range is None:
    raise ValueError("reference-stat-range must be provided; see help")
ref_min_stat, ref_max_stat= get_stat_range(opts.reference_stat_range)

if opts.test_threshold is None:
    raise ValueError("test-threshold must be provided; see help")
test_threshold = opts.test_threshold
if opts.reference_threshold is None:
    raise ValueError("reference-threshold must be provided; see help")
ref_threshold = opts.reference_threshold

# load the layers
print "loading layers"
layers = efficiency.create_layers_from_config(opts.layer_config_file,
    cube_type='gain')

# create the directory structure: layer0 goes in the top level folder.
# Each sub-layer are placed in sub-folders. Every folder has an images
# directory where plots are stored.
imgdir = 'images'
scriptdir = 'scripts/'
this_folder = '/'
for ii,layer in enumerate(layers):
    try:
        os.mkdir('%s%s' %(opts.output_dir, this_folder))
    except OSError:
        pass
    # make the images folder
    try:
        os.mkdir('%s%s%s' %(opts.output_dir, this_folder, imgdir))
    except OSError:
        pass
    # make scripts foler if necessary
    if opts.mapper is not None:
        try:
            os.mkdir('%s%s%s' %(opts.output_dir, this_folder, scriptdir))
        except OSError:
            pass
        shutil.copy2(opts.mapper, '%s%s%s' %(
            opts.output_dir, this_folder, scriptdir)) 
        mapper = '%s/%s' %(scriptdir, os.path.basename(opts.mapper))
    else:
        mapper = None
    layer.root_dir = opts.output_dir
    layer.web_dir = this_folder
    layer.images_dir = imgdir
    # update this_folder for the next lower layer
    this_folder = '%slevel%i/'%(this_folder, ii+1) 

# if an astrophysical prior is desired, set it for all of the cubes
if astprior is not None:
    for pcube in efficiency.get_all_cubes_in_layers(layers[0]):
        pcube.reference_cube.set_astro_prior(astprior)
        pcube.test_cube.set_astro_prior(astprior)

# if additional plots cache are specified, load them
if opts.additional_plots_cache is not None:
    print "creating symbolic links to additional plots..."
    plot_cache = {}
    # get this layer config file's checksum for comparison
    layers_checksum = efficiency.get_layers_checksum(layers[0])
    for cache in opts.additional_plots_cache.split(','):
        _, this_checksum, this_cache = efficiency.load_plot_cache(cache) 
        if this_checksum != layers_checksum:
            raise ValueError("the layer hierarchy in " +\
                "plot cache %s does not have the same checksum " %(cache) +\
                "as the layer hierarchy from the given layer-config-file")
        for tile_layer_id, filelist in this_cache.items():
            plot_cache.setdefault(tile_layer_id, [])
            plot_cache[tile_layer_id] += filelist
    this_layer = layers[0]
    while this_layer is not None:
        # if the bottom layer, also create links for the additional plots
        # to the children
        if this_layer.sub_layer is None:
            pcubes = this_layer.parents + this_layer.all_children
        else:
            pcubes = this_layer.parents
        for ii,pcube in enumerate(pcubes):
            add_plots = plot_cache[pcube.id_in_layer]
            for jj,plot in enumerate(add_plots):
                # create a symbolic link to the plot in the layer's image dir
                figname = '%s%s%s/%i_%i-%s' %(this_layer.root_dir,
                    this_layer.web_dir, this_layer.images_dir,
                    ii, jj, os.path.basename(plot))
                # ensure that we can create a symlink
                try:
                    os.remove(figname)
                except OSError:
                    pass
                os.symlink(plot, figname)
                # add the figname to the pcube's additional plots
                pcube.additional_plots.append(figname)
        this_layer = this_layer.sub_layer

# get the dictionary needed to apply cuts
apply_cut = {}
for thiscut in opts.apply_cut:
    arg, vals = thiscut.split(':')
    apply_cut[arg] = map(float, vals.split(','))

print "getting test results"
filenames = plot.parse_results_cache(test_cache)
if test_results_type == "overlaps":
    test_results, _ = plot.overlaps.get_injection_results(filenames,
        load_inj_distribution=True, verbose=True)
elif test_results_type == "pycbc_sqlite":
    test_results, _ = plot.pycbc_sqlite.get_injection_results(filenames,
        opts.map_label,
        load_inj_distribution=opts.astrophysical_prior is not None,
        verbose=True)
elif test_results_type == "gstlal":
    test_results, _ = plot.gstlal.get_injection_results(filenames,
        load_inj_distribution=opts.astrophysical_prior is not None,
        verbose=True)
elif test_results_type == "hdfcoinc":
    injfind_files = plot.hdfcoinc.get_hdfinjfind_files_from_filelist(
        filenames)
    injection_files = plot.hdfcoinc.get_injection_files_from_filelist(
        filenames)
    statmap_files = plot.hdfcoinc.get_fulldata_statmap_file_from_filelist(
        filenames)
    test_results, _ = plot.hdfcoinc.get_injection_results(injfind_files,
        sim_inspiral_files=injection_files,
        load_inj_distribution=opts.astrophysical_prior is not None,
        verbose=True)

if opts.include_livetime:
    if test_results_type == "pycbc_sqlite":
        # we only need the simulation livetimes
        test_livetime = plot.pycbc_sqlite.get_livetime(filenames
            )['simulation']
        # Since all of the on_instruments are gathered, and since, by
        # by definition, the on_instrument times do not intersect, we will
        # just add them all up
        # Note: I'm ignoring the veto_def_name here; this can lead to
        # errors if there are multiple vetoe cats in a single database;
        # in that case, I'll just raise an error
        if len(set([veto_cat for (_,veto_cat) in livetime])) != 1:
            raise ValueError("file %s has multiple veto categorgies, but " +\
                "I can only handle one veto category in each file; sorry!")
        test_livetime = sum([dur for _,dur in livetime.values()])
    elif test_results_type == "gstlal":
        test_livetime = plot.gstlal.get_livetime(filenames)
        test_livetime = sum([dur for dur in test_livetime.values()])
    elif test_results_type == "hdfcoinc":
        test_livetime = plot.hdfcoinc.get_livetime(statmap_files) 
    print "test livetime (s): ", test_livetime
else:
    test_livetime = None

if apply_cut:
    print "applying cuts"
    test_results = plot.slice_results(test_results, apply_cut)

if opts.reference_stat != 'optimal':
    print "getting reference results"
    filenames = plot.parse_results_cache(ref_cache)
    if ref_results_type == "overlaps":
        ref_results, _ = plot.overlaps.get_injection_results(filenames,
            load_inj_distribution=True, verbose=True)
    elif ref_results_type == "pycbc_sqlite":
        ref_results, _ = plot.pycbc_sqlite.get_injection_results(filenames,
            opts.map_label,
            load_inj_distribution=opts.astrophysical_prior is not None,
            verbose=True)
    elif ref_results_type == "gstlal":
        ref_results, _ = plot.gstlal.get_injection_results(filenames,
            load_inj_distribution=opts.astrophysical_prior is not None,
            verbose=True)
    elif ref_results_type == "hdfcoinc":
        injfind_files = plot.hdfcoinc.get_hdfinjfind_files_from_filelist(
            filenames)
        injection_files = plot.hdfcoinc.get_injection_files_from_filelist(
            filenames)
        statmap_files = plot.hdfcoinc.get_fulldata_statmap_file_from_filelist(
            filenames)
        ref_results, _ = plot.hdfcoinc.get_injection_results(injfind_files,
            sim_inspiral_files=injection_files,
            load_inj_distribution=opts.astrophysical_prior is not None,
            verbose=True)
    if opts.include_livetime:
        if ref_results_type == "pycbc_sqlite":
            # we only need the simulation livetimes
            ref_livetime = plot.pycbc_sqlite.get_livetime(filenames
                )['simulation']
            # Since all of the on_instruments are gathered, and since, by
            # by definition, the on_instrument times do not intersect, we will
            # just add them all up
            # Note: I'm ignoring the veto_def_name here; this can lead to
            # errors if there are multiple vetoe cats in a single database;
            # in that case, I'll just raise an error
            if len(set([veto_cat for (_,veto_cat) in livetime])) != 1:
                raise ValueError("file %s has multiple veto categorgies, but " +\
                    "I can only handle one veto category in each file; sorry!")
            ref_livetime = sum([dur for _,dur in livetime.values()])
        elif ref_results_type == "gstlal":
            ref_livetime = plot.gstlal.get_livetime(filenames)
            ref_livetime = sum([dur for dur in ref_livetime.values()])
        elif ref_results_type == "hdfcoinc":
            ref_livetime = plot.hdfcoinc.get_livetime(statmap_files) 
        print "ref. livetime (s): ", ref_livetime
    else:
        ref_livetime = None
else:
    # just set the reference data to be the same as the test
    ref_results = test_results
    ref_label = 'optimal'
    ref_livetime = test_livetime

print "Number of test results: %i" % len(test_results)
print "Number of reference results: %i" % len(ref_results)

# set the top level data and ranking parameters
print "binning data"
layers[0].set_cube_data(test_results, 'test')
layers[0].set_ranking_params(test_stat, test_rank_by, test_stat_label, 'test')
layers[0].set_cube_data(ref_results, 'reference')
layers[0].set_ranking_params(ref_stat, ref_rank_by, ref_stat_label,
    'reference')

# now go down through the other layers, set the rest of the data
next_layer = layers[0].sub_layer
while next_layer is not None:
    next_layer.set_cube_data_using_super()
    next_layer.set_ranking_params(test_stat, test_rank_by, test_stat_label,
        'test')
    next_layer.set_ranking_params(ref_stat, ref_rank_by, ref_stat_label,
        'reference')
    next_layer = next_layer.sub_layer

# if desired, set the global normalization
if opts.use_global_norm:
    # if no astro prior is specified, this is just the total number of
    # injections
    if astprior is None:
        norm = float(len(results))
    # otherwise, the norm is the sum of the weights of all of the injections
    else:
        test_weights = numpy.array([distributions.convert_distribution(
            x, x.injection.mass_distr, astprior) for x in test_results
            if x.injection.vol_weight is not None])
        test_norm = test_weights.sum() 
        ref_weights = numpy.array([distributions.convert_distribution(
            x, x.injection.mass_distr, astprior) for x in ref_results
            if x.injection.vol_weight is not None])
        ref_norm = ref_weights.sum() 
    # now set the global norm for all the phyper cubes
    for pcube in efficiency.get_all_cubes_in_layers(layers[0]):
        pcube.test_cube.global_norm = test_norm
        pcube.reference_cube.global_norm = ref_norm
        # also set the total number of injections for computing the variance
        pcube.test_cube.total_nsamples = len(test_results)
        pcube.reference_cube.total_nsamples = len(ref_results)

# color options
mingain = opts.mingain
maxgain = opts.maxgain
minvol = maxvol = None
logz = not opts.linz

# for keeping track of commands, we'll add the arguments used to create this
# at the bottom of the html pages
command_line = print_command_line(sys.argv)

# Plot
print "plotting"
html_tmplt = '%slevel_%i-%s_%i.html'
# we'll create the plots from the bottom layers up, so that we can provide
# links to each lower layer
this_layer = layers[-1]
while this_layer is not None:
    # for the bottom layer, we'll also create html and volume vs stat plots
    # for the children
    this_is_lowest_layer = this_layer.sub_layer is None
    if not opts.skip_volume_vs_stat_plots:
        plot_volumes.plot_twovolume_vs_stat_from_layer(this_layer,
            test_min_stat, test_max_stat, ref_min_stat, ref_max_stat,
            test_threshold, ref_threshold, test_livetime=test_livetime,
            ref_livetime=ref_livetime, test_label=test_label,
            ref_label=ref_label, include_children=this_is_lowest_layer,
            user_tag=opts.user_tag, min_ninj=opts.min_ninj, logx=not
            opts.lin_stat, logy=opts.log_vol_vs_stat, nbins=100, dpi=opts.dpi,
            verbose=True)

    plot_volumes.plot_gains_from_layer(this_layer, test_threshold,
        ref_threshold, test_livetime=test_livetime, ref_livetime=ref_livetime,
        user_tag=opts.user_tag, min_ninj=opts.min_ninj,
        test_label=test_label, ref_label=ref_label, colormap=opts.colormap,
        maxgain=maxgain, mingain=mingain, fontsize=opts.fontsize,
        print_relative_err=opts.print_relative_error,
        logz=logz, include_volume_plots=opts.include_volume_plots,
        minvol=minvol, maxvol=maxvol, dpi=opts.dpi, verbose=True)

    # if not the last layer, create the subvolumes plot
    if this_layer.sub_layer is not None:
        plot_volumes.plot_subgains_from_layer(this_layer, test_threshold,
            ref_threshold,
            test_livetime=test_livetime, ref_livetime=ref_livetime,
            user_tag=opts.user_tag, min_ninj=opts.min_ninj,
            test_label=test_label, ref_label=ref_label, colormap=opts.colormap,
            maxgain=maxgain, mingain=mingain,
            logz=logz, dpi=opts.dpi, verbose=True)

    # write the html page
    # if this is the bottom layer, create pages for the children
    if this_is_lowest_layer:
        for ii,child in enumerate(this_layer.all_children):
            html_name = html_tmplt %(this_layer.web_dir, this_layer.level,
                'child', ii)
            child.create_html_page(this_layer.root_dir, html_name,
                test_threshold, ref_threshold, test_label=test_label,
                ref_label=ref_label,mapper=None,
                ref_livetime=ref_livetime, test_livetime=test_livetime,
                print_relative_error=opts.print_relative_error,
                comments=command_line)
    # the top layer page is the index page; otherwise we use the template
    for ii,parent in enumerate(this_layer.parents):
        if this_layer.level == 0:
            html_name = '/index.html'
        else:
            html_name = html_tmplt %(this_layer.web_dir, this_layer.level,
                'parent', ii)
        parent.create_html_page(this_layer.root_dir, html_name, test_threshold,
            ref_threshold, test_label=test_label, ref_label=ref_label,
            mapper=mapper,
            ref_livetime=ref_livetime, test_livetime=test_livetime,
            print_relative_error=opts.print_relative_error,
            comments=command_line)

    this_layer = this_layer.super_layer
